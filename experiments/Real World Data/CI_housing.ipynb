{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import kendalltau \n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "\n",
    "# data loading\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "\n",
    "def generate_data(n, m):\n",
    "    sampled_data = df.sample(n=n, replace=True)\n",
    "    v, w = sampled_data[\"MedInc\"].to_numpy(), sampled_data[\"MedHouseVal\"].to_numpy()\n",
    "    x = sampled_data.drop(columns=[\"MedInc\", \"MedHouseVal\"]).values\n",
    "\n",
    "    sampled_data_unlabel = df.sample(n=m, replace=True)\n",
    "    x_unlabel = sampled_data_unlabel.drop(columns=[\"MedInc\", \"MedHouseVal\"]).values\n",
    "\n",
    "    return x, x_unlabel, v, w\n",
    "\n",
    "\n",
    "def Ucross(x, x_unlabel, v, w):\n",
    "    \n",
    "    x_a, x_b, v_a, v_b, w_a, w_b = train_test_split(x, v, w, test_size=0.5)\n",
    "    x_unlabel_a, x_unlabel_b = train_test_split(x_unlabel, test_size=0.5)\n",
    "\n",
    "    def fit_model(x, y):\n",
    "        model = XGBRegressor()\n",
    "        model.fit(x, y)\n",
    "        return model\n",
    "    \n",
    "    def compute_ecdfs(v_split, w_split):\n",
    "        n = len(v_split)\n",
    "        ecdf_v = np.sum(v_split[:, None] <= v_split, axis=0) / n\n",
    "        ecdf_w = np.sum(w_split[:, None] <= w_split, axis=0) / n\n",
    "        ecdf_vw = np.sum((v_split[:, None] <= v_split) & (w_split[:, None] <= w_split), axis=0) / n\n",
    "        return ecdf_v, ecdf_w, ecdf_vw\n",
    "\n",
    "    def compute_ell1(ecdf_v, ecdf_w, ecdf_vw):\n",
    "        return (1 - 2 * ecdf_v) * (1 - 2 * ecdf_w) + 4 * (ecdf_vw - ecdf_v * ecdf_w)\n",
    "\n",
    "    ecdf_v_a, ecdf_w_a, ecdf_vw_a = compute_ecdfs(v_a, w_a)\n",
    "    ecdf_v_b, ecdf_w_b, ecdf_vw_b = compute_ecdfs(v_b, w_b)\n",
    "\n",
    "    ell1_a = compute_ell1(ecdf_v_a, ecdf_w_a, ecdf_vw_a)\n",
    "    ell1_b = compute_ell1(ecdf_v_b, ecdf_w_b, ecdf_vw_b)\n",
    "    ell1_cross = np.concatenate((ell1_a, ell1_b))\n",
    "\n",
    "    model_a = fit_model(x_a, ell1_a)\n",
    "    fhat_label_b = model_a.predict(x_b)\n",
    "    fhat_unlabel_b = model_a.predict(x_unlabel_b)\n",
    "    \n",
    "    model_b = fit_model(x_b, ell1_b)\n",
    "    fhat_label_a = model_b.predict(x_a)\n",
    "    fhat_unlabel_a = model_b.predict(x_unlabel_a)\n",
    "    \n",
    "    fhat_label_cross = np.concatenate((fhat_label_a, fhat_label_b))\n",
    "    fhat_label_unlabel_cross = np.concatenate((fhat_label_cross, fhat_unlabel_a, fhat_unlabel_b))\n",
    "    \n",
    "    # Ucross stat\n",
    "    U = kendalltau(v, w)[0]\n",
    "    Ucross = U - np.mean(fhat_label_cross) + np.mean(fhat_label_unlabel_cross)\n",
    "    \n",
    "    gamma1 = np.mean((ell1_a - np.mean(ell1_a)) * (fhat_label_a - np.mean(fhat_label_a))) \\\n",
    "             / np.var(np.concatenate((fhat_label_a, fhat_unlabel_a)))\n",
    "    gamma2 = np.mean((ell1_b - np.mean(ell1_b)) * (fhat_label_b - np.mean(fhat_label_b))) \\\n",
    "             / np.var(np.concatenate((fhat_label_b, fhat_unlabel_b)))\n",
    "             \n",
    "    Ucross_cv = U - np.mean(np.concatenate((gamma1 * fhat_label_a, gamma2 * fhat_label_b))) \\\n",
    "                         + np.mean(np.concatenate((gamma1 * fhat_label_a, gamma2 * fhat_label_b, gamma1 * fhat_unlabel_a, gamma2 * fhat_unlabel_b)))\n",
    "    \n",
    "    \n",
    "    # variance \n",
    "    n = len(x)\n",
    "    m = len(x_unlabel)\n",
    "    \n",
    "    Ui = []\n",
    "    for i in range(n):\n",
    "        v_leave_one_out = np.delete(v, i)\n",
    "        w_leave_one_out = np.delete(w, i)\n",
    "        Ui.append(kendalltau(v_leave_one_out, w_leave_one_out)[0])\n",
    "\n",
    "    Ui = np.array(Ui)\n",
    "    sigma2 = (n - 1) / 4 * np.sum((Ui - U)**2)\n",
    "    tau = np.mean((fhat_label_cross - ell1_cross - np.mean(fhat_label_cross - ell1_cross))**2) - sigma2\n",
    "    var_U = 4 * sigma2\n",
    "    var_Ucross = 4 * sigma2 + 4 * m / (n + m) * tau\n",
    "    return U, Ucross, var_U, var_Ucross   \n",
    "# population kendall tau\n",
    "pop_kendall_tau = kendalltau(df[\"MedInc\"], df[\"MedHouseVal\"])[0]\n",
    "\n",
    "\n",
    "def simulation(n, m):\n",
    "    x, x_unlabel, v, w = generate_data(n, m)\n",
    "    U, Uss, var_U, var_Uss = Ucross(x, x_unlabel, v, w)\n",
    "\n",
    "    lb = U - 1 / np.sqrt(n) * norm.ppf(0.975) * np.sqrt(var_U)\n",
    "    ub = U + 1 / np.sqrt(n) * norm.ppf(0.975) * np.sqrt(var_U)\n",
    "\n",
    "    lb_ss = Uss - 1 / np.sqrt(n) * norm.ppf(0.975) * np.sqrt(var_Uss)\n",
    "    ub_ss = Uss + 1 / np.sqrt(n) * norm.ppf(0.975) * np.sqrt(var_Uss)\n",
    "\n",
    "    count_in_ci = ((lb <= pop_kendall_tau) & (pop_kendall_tau <= ub)).sum()\n",
    "    count_in_ci_ss = ((lb_ss <= pop_kendall_tau) & (pop_kendall_tau <= ub_ss)).sum()\n",
    "\n",
    "    avg_length_ci = (ub - lb).mean()\n",
    "    avg_length_ci_ss = (ub_ss - lb_ss).mean()\n",
    "\n",
    "    return count_in_ci, count_in_ci_ss, avg_length_ci, avg_length_ci_ss\n",
    "\n",
    "\n",
    "results_dict = {}\n",
    "n_seq = [1000, 1200, 1400, 1600, 1800, 2000]\n",
    "\n",
    "for n in n_seq:\n",
    "    m = n * 10\n",
    "    results = Parallel(n_jobs=-1)(delayed(simulation)(n, m) for _ in tqdm(range(10000), desc=f\"n={n}\"))\n",
    "    count_in_ci_list, count_in_ci_ss_list, avg_length_ci_list, avg_length_ci_ss_list = zip(*results)\n",
    "\n",
    "    results_dict[n] = {\n",
    "        \"count_in_ci\": np.mean(count_in_ci_list),\n",
    "        \"count_in_ci_ss\": np.mean(count_in_ci_ss_list),\n",
    "        \"avg_length_ci\": np.mean(avg_length_ci_list),\n",
    "        \"avg_length_ci_ss\": np.mean(avg_length_ci_ss_list),\n",
    "        \"se_length_ci\": np.std(avg_length_ci_list, ddof=1) / np.sqrt(len(avg_length_ci_list)),\n",
    "        \"se_length_ci_ss\": np.std(avg_length_ci_ss_list, ddof=1) / np.sqrt(len(avg_length_ci_ss_list)),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Use LaTeX for text rendering and set professional font\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"cmr10\"],\n",
    "    \"axes.titlesize\": 20,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"legend.fontsize\": 16\n",
    "})\n",
    "\n",
    "color_u = \"#0072BD\"  \n",
    "color_ucross = \"#D95319\" \n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Average Count Plot (Coverage Probability)\n",
    "axes[0].plot(n_seq, [results_dict[n][\"count_in_ci\"] for n in n_seq], \n",
    "             marker='o', markersize=7, linestyle='-', linewidth=2, color=color_u, label=r'$U$')\n",
    "axes[0].plot(n_seq, [results_dict[n][\"count_in_ci_ss\"] for n in n_seq], \n",
    "             marker='s', markersize=7, linestyle='-', linewidth=2, color=color_ucross, label=r'$U_{\\mathrm{cross}}$')\n",
    "axes[0].axhline(y=0.95, color='gray', linestyle='--', linewidth=1.2)\n",
    "axes[0].set_xlabel(r'$n$')\n",
    "axes[0].set_ylabel(r'Coverage')\n",
    "axes[0].set_ylim(0.8, 1.0)\n",
    "axes[0].legend(loc='lower left')\n",
    "axes[0].set_title(r'Coverage Probability of Confidence Interval')\n",
    "axes[0].grid(True, linestyle='--', linewidth=0.5, alpha=0.7)  # Add gridlines\n",
    "\n",
    "# Average Length Plot (without error bars)\n",
    "axes[1].plot(n_seq, [results_dict[n][\"avg_length_ci\"] for n in n_seq],\n",
    "             marker='o', markersize=7, linestyle='-', linewidth=2, color=color_u, label=r'$U$')\n",
    "axes[1].plot(n_seq, [results_dict[n][\"avg_length_ci_ss\"] for n in n_seq],\n",
    "             marker='s', markersize=7, linestyle='-', linewidth=2, color=color_ucross, label=r'$U_{\\mathrm{cross}}$')\n",
    "axes[1].set_xlabel(r'$n$')\n",
    "axes[1].set_ylabel(r'Width')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].set_title(r'Average Width of Confidence Interval')\n",
    "axes[1].grid(True, linestyle='--', linewidth=0.5, alpha=0.7)  # Add gridlines\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(output_dir, 'CI_Housing.pdf'), format='pdf')\n",
    "plt.show()\n",
    "\n",
    "print(f\"PDF: {os.path.join(output_dir, 'CI_Housing.pdf')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
